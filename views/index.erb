<html>
<head>
  <title>Machine Learning: Notes</title>
  <link rel="stylesheet" href="/css/app.css" type="text/css">
  <script type="text/javascript">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      processEscapes: true
    }
  });
  </script>
	<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
	</script>
</head>
<body>
  <div id="content">
	<h1>Machine Learning</h1>
	<p>Notes on Stanford's online course <a href="http://ml-class.org">Machine Learning</a> 
	  <br />
These notes are updated as the course progresses.
	  </p>
  	<h2>II. Linear Regression with One Variable</h2>
  	<h2>III. Linear Algebra</h2>
  	<h2>IV. Linear Regression with Multiple Variables</h2>



	<h2>VI. Logistic Regression</h2>
	<p>
	  Classification algorithm used for prediction of the probability of occurrence of an event by fitting data to a logit function logistic curve.
	</p>
	<h3>Hypothesis Representation</h3>
	  <p>
	  In logistic regression, we want the hypothesis to be <script type="math/tex">0 \le h_\theta(x) \le 1 </script>. <br />
	  For this, we use the <i>Sigmoid or Logistic Function</i>  
    </p> 
  
  
      <div class="figure">
        <p>      <img style="margin-bottom:20px;" alt="sigmoid function" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/320px-Logistic-curve.svg.png" width="240">    
        <p>Plot of \(g(z)\)
      </div>
  
  <p>
      
  
    $$
    \begin{eqnarray}
    g(z) &=& { \frac{1}{1 + e^{-z}} } \\
    h_\theta(x) &=& g(\theta^T x)  \\\\

    h_\theta(x) &=& { \frac{1}{1 + e^{-\theta^T x}} } 
    \end{eqnarray}  
    $$
  </p>
  <div style="clear:both;" />
  <p>In Octave it looks something like the following</p>
  <script src="https://gist.github.com/1329789.js?file=gistfile1.matlab"></script>
      <div style="clear:both;" />
  
  
  
	<h3>Interpretation of Hypothesis Output</h3>
	<p>
    \(h_\theta(x) =\) estimated probability that \(y = 1\) on input \(x\)
	</p>
	<p>
    \(h_\theta(x) = P(y=1|x;\theta)\)
  </p>
  <p>
    <script type="math/tex">
    \begin{eqnarray}
    P(y=1|x;\theta) + P(y=0|x;\theta) &=& 1 \\  
    P(y=0|x;\theta) &=& 1 - P(y=1|x;\theta)
    \end{eqnarray}
    </script>
  </p>
  
  <h3>Decision Boundary</h3>
	<p>
    \(g(z) \ge 0.5\) when \(z \ge 0 \)
	</p>
	<p>
   since \(h_\theta(x) = g(\theta^T x)\), then \(g(\theta^T x) \ge 0.5\)  when \(\theta^T x \ge 0 \)
	</p>
	<ul>
	  <li>Suppose predict \(y=1\) if \(h_\theta(x) \ge 0.5 \) and \(y=0\) if \(h_\theta(x) \lt 0.5 \)</li>
	  <li>\(y=1\) when \(\theta^T x \ge 0\)</li>
	  <li>  The decision boundary is a property of the hypothesis and it's parameters, not the dataset.</li>
	</ul>
	
  <h3>Logistic Regression Cost Function</h3>
  <p>
    For logistic regression, the cost function that us used for linear regression produces a "non-convex" function of the parameters \(\theta\). What we would like instead is a function that is "convex" (single bow shaped function). Using a convex function guarantees that gradient descent can find the global minimum.
  </p>
  <p>
    $$
    \begin{eqnarray}
      J(\theta) &=& \frac{1}{m}\sum_{i=1}^m{\text{Cost}(h_\theta(x^{(i)}),y^{(i)})} \\
      \text{Cost}(h_\theta(x), y)&=&\begin{cases}
        -\log(h_\theta(x)), & \text{if $y=1$}.\\
        -\log(1 - h_\theta(x)), & \text{if $y=0$}.
      \end{cases}
    \end{eqnarray}
    $$
    <ul>
      <li>Note: \(y=0\) or 1 always</li>
      <li>if \(y = 1\), as \(h_\theta(x) \rightarrow 1\), Cost \(\rightarrow 0\)<br />
      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and as \(h_\theta(x) \rightarrow 0\), Cost \(\rightarrow \infty\)<br />
      so if \(y = h_\theta(x) \), Cost will be 0 for \(y = 1\) or \(y = 0\)</li>
    </ul>
  </p>
  
  
  <h3>Simplified Cost Function and Gradient Decent</h3> 
  <p>The cost function can be simplified to the following form</p> 
  <p>
    
    $$  \text{Cost}(h_\theta(x), y) = -y\log(h_\theta(x)) - (1-y)\log(1-h_\theta(x)) $$
  </p>
  <p>This compaction comes from statistics: the principle of maximum likelihood estimation</p>
<p>
  Finally, plugging this back in we arrive at our <b>simplified cost function for logistic regression</b>
  </p>
  <p>
      $$ J(\theta) = -\frac{1}{m}\bigg[
      \sum_{i=1}^m{y^{(i)}\log(h_\theta(x^{(i)})) - (1-y^{(i)})\log(1-h_\theta(x^{(i)}))}
      \bigg] 
      $$
      
      and the gradient of the cost is a vector Î¸ where the jth element (for j = 0,1,...,n) is defined as follows:
      
      $$
        \frac{\partial J(\theta)}{\partial\theta_j} = \frac{1}{m} \sum_{i=1}^m{y^{(i)}}(h_\theta(x^{(i)})-y^{(i)}) x_j^{(i)}
      $$
  </p>

  <p>
    In order to minimize the value of \(J(\theta)\) for <i>logistic regression</i> we also use <i>gradient descent</i>. It turns out that the algorithm looks identical to that used for <i>linear regression</i>! The difference is in the value at \(h_\theta(x)\), which for logistic regression is \(    h_\theta(x) = { \frac{1}{1 + e^{-\theta^T x}} }  \). For completeness,  <b>gradient descent for logistic regression</b> is as follows:
    
    $$
    \begin{eqnarray}
      \theta_j &:=& \theta_j - \alpha \frac{\partial}{\partial\theta_j} J(\theta) \\
      \text{which simplifies to}\\
      \theta_j &:=& \theta_j - \alpha \sum_{i=1}^m{ (h_\theta(x^{(i)}) - y^{(i)}) x_j^{(i)} }
      \end{eqnarray}
    $$
    
  </p>
  <p>
    In Octave, this equation looks like this
    <script src="https://gist.github.com/1329765.js?file=gistfile1.matlab"></script>
  </p>
  
  <h3>Advanced Optimization</h3>
  
  
  
  <!-- REGULARIZATION -->
  <h2>VII. Regularization</h2>
  
  
  
  <!-- REGULARIZATION -->
  <h2>VIII. Neural Networks</h2>
  <p>
    Neural networks are classifiers that produce complex non-linear decision boundaries.
  </p>

    <img style="margin-bottom:20px;" alt="sigmoid function" src="images/neural_network.png" width="480">    

  <div style="clear:both;" />

  <p>

    <script type="math/tex">a_i^{(j)}</script> = "activation" of unit i in layer j<br />
    <script type="math/tex">\Theta^{(j)}</script> = matrix of weights controlling function mapping from layer j to layer j + 1
    
  </p>
  <p>
    <script type="math/tex">
      \begin{eqnarray}
        a_1^{(2)} &=& g(\Theta_{10}^{(1)} x_0 + \Theta_{11}^{(1)} x_1 + \Theta_{12}^{(1)} x_2 + \Theta_{13}^{(1)} x_3)\\
        a_2^{(2)} &=& g(\Theta_{20}^{(1)} x_0 + \Theta_{21}^{(1)} x_1 + \Theta_{22}^{(1)} x_2 + \Theta_{23}^{(1)} x_3)\\
        a_3^{(2)} &=& g(\Theta_{30}^{(1)} x_0 + \Theta_{31}^{(1)} x_1 + \Theta_{32}^{(1)} x_2 + \Theta_{33}^{(1)} x_3)  \\      
        h_{\Theta}(x) &=& a_1^{(3)} = g(\Theta_{10}^{(2)} a_0^{(2)} + \Theta_{11}^{(2)} a_1^{(2)} + \Theta_{12}^{(2)} a_2^{(2)} + \Theta_{13}^{(2)} a_3^{(2)})        
      \end{eqnarray}
    </script>
  </p>
  <p>
    If network has \(s_j\) units in layer \(j\), \(s_{j+1}\) units in layer \(j + 1\), then \(\Theta^{(j)}\) will be of dimension \(s_{j+1} \text{x} (s_j + 1)\)
  </p>
  
	</div>
</body>
</html>